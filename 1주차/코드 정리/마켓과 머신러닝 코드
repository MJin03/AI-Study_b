# 생선의 길이가 30cm이상 이면 도미이다.
if fish_lengtg >= 30:
  print("도미")

* 도미
# 생선의 길이 _ 도미
bream_length = [25.4, 26.3, 31.0, 31.0, 31.5, 32.0, 34.0, 34.0, 34.5, 35.0, 26.5, 29.0, 29.0, 29.7, 29.7, 32.0, 32.0, 33.0,
35.0, 35.0, 35.0, 30.0, 30.0, 30.7, 33.0, 33.5, 33.5, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]

# 생선의 무게 _ 도미
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 
700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0,
925.0, 975.0, 950.0]

# 산점도 _ 도미
# matplotlib의 pyplot 함수를 pit로 줄여서 사용
import matplotlib.pyplot as pit 

pit.scatter(bream_length, bream_weight)
plt.xlabel('length') # x축 = 길이 -> 화면에 표시
pit.ylabel('weight') # y축 = 무게 -> 화면에 표시
plt.show()


*빙어
# 생선의 길이 _ 빙어
smelt_length = [ 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2,
12.4, 13.0, 14.3, 15.0]

# 생선의 무게 _ 빙어
smelt_weight [ 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4,
12.2, 19.7, 19.9]

* 산점도 _ 빙어
plt. scatter(bream_lengtfi, bream_weight)
pit.scatter(smelt_length, smelt_weight)
plt.xlabel('length’)
plt.ylabel('weight')
plt.show()


# 도미 + 빙어 데이터
length = bream_length + smelt_length
weight = bream_weight + smelt_length

# length와 weight 리스트 -> 2차원 리스트
fish_data = [[l,w] for l, w in zip(length, weight)] 
  #zip() 함수로 length와 weight 리스트에서 원소를 하나씩 꺼내어 l과 w에 할당.
  #zip() 함수: 나열된 리스트에서 각각 하나씩 원소를 꺼내 변환.

# 컴퓨터 프로그램은 문자를 직접 이해X -> 0과 1로 표현, 찾으려는 값 = 1. (도미 = 1, 빙어 = 0)
# 기존 2차원 리스트
 [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0] , [29.0, 430.0]
 [29.7, 450.0], [29.7, 500.0], [30.0, 390.0], [30.0, 450.0], [30.7, 500.0],
 [31.0, 475.0], [31.0, 500.0], [31.5, 500.0], [32.0, 340.0], [32.0, 600.0],
 [32.0, 600.0], [33.0, 700.0], [33.0, 700.0], [33.5, 610.0], [33.5, 650.0], 
 [34.0, 575.0], [34.0, 685.0], [34.5, 620.0], [35.0, 680.0], [35.0, 700.0], 
 [35.0, 725.0], [35.0, 720.0], [36.0, 714.0], [36.0, 850.0], [37.0, 1000.0],
 [38.5, 920.0], [38.5, 955.0], [39.5, 925.0], [41.0, 975.0], [41.0, 950.0],
 [9.8, 6.7], [10.5, 7.5], [10.6, 7.0], [11.0, 9.7], [11.2, 9.8], [11.3, 8.7],
 [11.8, 10.0], [11.8, 9.9], [12.0, 9.8], [12.2, 12.2], [12.4, 13.4],
 [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]]

# 도미 35번, 빙어 14번 나옴
fish_target = [1] * 35 + [0] * 14

[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
 # 0과 1로 출력


# 사이킷런 패키지에서 k-푀근접 이웃 알고리즘 을 구현한 클래스 KNeighborsClassifier 임포트.
kn = KNeighborsClassifier()
  # 이 객체에 fish_data와 fish_target을 전달하여 도미를 찾기 위한 기준을 학습시킴. -> "훈련" 이라고 함. -> fit() 메서드 사용.

# fit() 메서드에 fish_data와 fish_target을 순서대로 전달.
kn.fit(fish_data, fish_target)

** fit()
: 주어진 데이터로 알고리즘을 훈련.

** score()
: 모델을 평가. 
  >> 0~1 사이의 값 반환.
  >>> 1: 모든 데이터를 정확히 맞혔다.  (0.5: 절반만 맞혔다.)

 kn.score(fish_data, fish_target
  >> 1.0 (정확히 맞힘.)

** predict ()
: 새로운 데이터의 정답을 예측.
>> fit() 메서드와 마찬가지로 리스트의 리스트(2중 리스트)를 전달.

# 참고 데이터를 49개로 한 kn49 모델.
 kn49 = KNeighborsClassifier(n_neithbors=49)

# 가장 가까운 데이터 49개를 사용하는 k-최근접 이웃 모델에 fish_data를 적용하면 fish_data에 있는 모든 생성을 사용하여 예측.
>> 어떤 데이터를 넣어도 도미로 예측. (fish_data의 데이터 49개 중에 도미가 35개로 다수를 차지하기 때문.)
kn49.fit(fish_data4 fish_target)
kn49.score(fish_data4 fish_target)
  >> 0.7142857142857143

  # fish_data에 있는 생선 중에 도미가 35개이고 빙어가 14개. -> kn49 모델은 도미만 올바르게 
맞히기 때문에 다음과 같이 정확도를 계산하면 score () 메서드와 같은 값을 얻을 수 있다.


+ 맷플롯립 패키지
: 파이썬에서 과학계산용 그래프를 그리는 대표적인 패키지
  - fit()
  - score()
  -  predict ()
>> 임포트(따로 만들어둔 파이썬 패키지(함수 묶음)를 사용하기 위해 불러오는 명렁어)를 사용해서 불러옴.
